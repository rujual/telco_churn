{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telco Churn Pipeline\n",
    "\n",
    "import kfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Required Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def read_data(file_name: InputPath('CSV')) -> 'pd.DataFrame':   \n",
    "    \n",
    "    #OutputPath('CSV'):\n",
    "        # -> NamedTuple('Outputs', [('Cols_drop', int),('Cols_retained', int)]):\n",
    "    \n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    \n",
    "    #This line may cause problems as file is on the system and not inside container\n",
    "\n",
    "    df_churn = pd.read_csv(file_name)\n",
    "    col1 = len(df_churn.columns)\n",
    "    df_churn = df_churn.drop(columns=[])\n",
    "    \n",
    "    empty_cols=['customerID', 'gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "           'tenure', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "           'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport',\n",
    "           'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "           'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n",
    "    \n",
    "    for i in empty_cols:\n",
    "        df_churn[i]=df_churn[i].replace(\" \",np.nan)\n",
    "\n",
    "    df_churn.drop('customerID','cluster number', axis=1, inplace=True)\n",
    "    df_churn = df_churn.dropna()\n",
    "    \n",
    "    col2 = len(df.columns)\n",
    "    #df_churn.to_csv('Cleaned_data.csv')\n",
    "    #out_path = \"./Cleaned_data.csv\"\n",
    "    \n",
    "    return df_churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_read_data = kfp.components.create_component_from_func(func = read_data, \n",
    "                                                          output_component_file = './read-data-func.yaml',\n",
    "                                                          base_image = 'fastgenomics/sklearn',\n",
    "                                                          packages_to_install = ['pandas','matplotlib','numpy','scikit-learn'])\n",
    "\n",
    "read_data_task = kfp_read_data(file_name = 'https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv')    #, out_file_name = 'Cleaned_data.csv')\n",
    "#,out_file_name = 'Cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## One-Hot-Encode\n",
    "\n",
    "from typing import NamedTuple\n",
    "from kfp.components import *\n",
    "\n",
    "def one_hot_encode(input_df: 'pd.DataFrame') -> 'pd.DataFrame': #file_name: InputPath('CSV')) -> OutputPath:\n",
    "                   \n",
    "#                    out_file1_name: str, \n",
    "#                    out_file2_name: str) -> NamedTuple('Outputs',\n",
    "#                                                       [('out_file1_name', OutputPath('CSV')),\n",
    "#                                                        ('out_file2_name', OutputPath('CSV'))]):\n",
    "    #out_file2_name: OutputPath('CSV')) -> None:\n",
    "    \n",
    "    ## Import Required Libraries\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import sklearn\n",
    "    \n",
    "    df_churn = input_df #pd.read_csv(file_name)  \n",
    "    \n",
    "    binary_cols = ['Partner','Dependents','PhoneService','PaperlessBilling']\n",
    "\n",
    "    for i in binary_cols:\n",
    "        df_churn[i] = df_churn[i].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    #Encoding column 'gender'\n",
    "    df_churn['gender'] = df_churn['gender'].replace({\"Male\":1,\"Female\":0})\n",
    "\n",
    "\n",
    "    category_cols = ['PaymentMethod','MultipleLines','InternetService','OnlineSecurity',\n",
    "                   'OnlineBackup','DeviceProtection',\n",
    "                   'TechSupport','StreamingTV','StreamingMovies','Contract']\n",
    "\n",
    "    for cc in category_cols:\n",
    "        dummies = pd.get_dummies(df_churn[cc], drop_first=False)\n",
    "        dummies = dummies.add_prefix(\"{}#\".format(cc))\n",
    "        df_churn.drop(cc, axis=1, inplace=True)\n",
    "        df_churn = df_churn.join(dummies)\n",
    "    \n",
    "    df_churn['Churn'] = df_churn['Churn'].replace({\"Yes\":1,\"No\":0})\n",
    "\n",
    "    \n",
    "    #saving files may need a PV allocation to container\n",
    "    #output of files as Named tuple may cause problems    \n",
    "    \n",
    "    #df_churn.to_csv('Oht_enc_data.csv')\n",
    "    #out_path = \"./Oht_enc_data.csv\"\n",
    "    return df_churn #out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_one_hot_encode = kfp.components.create_component_from_func(func = one_hot_encode, \n",
    "                                                          output_component_file = './one-hot-encode-func.yaml',\n",
    "                                                          base_image = 'fastgenomics/sklearn',\n",
    "                                                          packages_to_install = ['pandas','matplotlib','numpy','scikit-learn'])\n",
    "one_hot_encode_task = kfp_one_hot_encode(read_data_task.outputs) #'Oht_enc_data.csv')  #,'One_Hot_encoded_data.csv','Churn_flags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest Model\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "def rf_model(input_df: 'pd.DataFrame', n_estimators: int = 100) -> NamedTuple('Outputs', [('Cf1', int), ('Cf2', int),\n",
    "                                                                                     ('Cf3', int), ('Cf4', int)]):\n",
    "#file_name: InputPath('CSV'), n_estimators: int) \n",
    "#ip_file1: InputPath('CSV'), ip_file2: InputPath('CSV'), modelopfile: OutputPath('joblib'))-> None:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    import joblib\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    df_churn = input_df #pd.read_csv(file_name)\n",
    "    n_est = n_estimators\n",
    "    y1 = df_churn['Churn']\n",
    "    X1 = dfc_churn.drop(['churn_flag'],axis=1)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X1, y1, random_state=0)\n",
    "    \n",
    "    sm = SMOTE(random_state=0)\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [2,4,5,6,7,8],\n",
    "        'criterion' :['gini', 'entropy']\n",
    "    }\n",
    "\n",
    "\n",
    "    rfc=RandomForestClassifier(random_state=42,n_estimators=n_est)\n",
    "    gsv_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    rfc.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "    #rfc_best = gsv_rfc.best_estimator_\n",
    "    rfc_best=RandomForestClassifier(random_state=42, max_features='auto', n_estimators= 50, max_depth=8,\n",
    "                                    criterion='gini')\n",
    "\n",
    "    rfc_best.fit(X_train_res, y_train_res)\n",
    "    X_test_res, y_test_res = sm.fit_sample(X_test, y_test)\n",
    "    y_test_pred = rfc_best.predict(X_test_res, y_test_res)\n",
    "    rf_score = rfc_best.score(X_test_res, y_test_res)\n",
    "    conf = confusion_matrix(y_test_res, y_test_pred)\n",
    "\n",
    "    return (conf[0][0],conf[0][1],conf[1][0],conf[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #dump the trained model in pickle file\n",
    "    #joblib.dump(rfc_best, modelopfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp_rf_model = kfp.components.create_component_from_func(func = rf_model, \n",
    "                                                          output_component_file = './rf-model-func.yaml',\n",
    "                                                          base_image = 'fastgenomics/sklearn',\n",
    "                                                          packages_to_install = ['pandas','matplotlib','numpy','scikit-learn','imbalanced-learn'])\n",
    "rf_model_task = kfp_rf_model(one_hot_encode_task.outputs, 100)     #('One_Hot_encoded_data.csv') #,'Churn_flags.csv','model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "\n",
    "@dsl.pipeline(name='Telco-Churn-Pipeline',description='A pipeline that processes Telco Churn dataset from Kaggle and performs ML-Predictions using Random Forest Algorithm')\n",
    "def Telco_Churn(file_name = \"https://raw.githubusercontent.com/rujual/telco_churn/master/Data.csv\", \n",
    "                n_estimators = 100):\n",
    "    read_data_task = kfp_read_data(file_name)\n",
    "    one_hot_encode_task = kfp_one_hot_encode(read_data_task.output)\n",
    "    rf_model_task = kfp_rf_model(one_hot_encode_task.output, n_estimators = 100)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = Telco_Churn\n",
    "pipeline_filename = pipeline_func.__name__+'.pipeline.'\n",
    "\n",
    "import kfp.compiler as comp\n",
    "comp.Compiler().compile(pipeline_func, pipeline_filename)  #, package_path='/home/My_Workplace/Telco_churn/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
